{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium.webdriver.common.by import By                             # By to get element using selector              \n",
    "from selenium import webdriver as wb                                    # wb to run the driver\n",
    "from selenium.webdriver.support import expected_conditions as EC        # EC to handle exception conditions\n",
    "from selenium.webdriver.support.ui import WebDriverWait as wait         # wait to handle wait conditions\n",
    "import pandas as pd                                                     # pd to export data\n",
    "from tqdm import tqdm                                                   # tqdm to visualize looping process\n",
    "from selenium.webdriver.common.keys import Keys                         # Keys as procedures using the keyboards\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# initialize driver Chrome to run simulation and get URL\n",
    "driver = wb.Chrome()\n",
    "driver.get('https://www.tokopedia.com/')\n",
    "\n",
    "driver.implicitly_wait(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize input to get keywords and pages\n",
    "keywords = input(\"Keywords: \")\n",
    "pages = int(input(\"Pages: \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize search to search by keywords and press ENTER\n",
    "search = driver.find_element(By.XPATH, '//*[@id=\"header-main-wrapper\"]/div[2]/div[2]/div/div/div/div/input')\n",
    "search.send_keys(keywords)\n",
    "search.send_keys(Keys.ENTER)\n",
    "\n",
    "driver.implicitly_wait(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize product_data to store product data as an array\n",
    "product_data = []\n",
    "\n",
    "# define scrolling to scroll page\n",
    "def scrolling():\n",
    "    scheight = .1\n",
    "    while scheight < 9.9:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight/%s);\" % scheight)\n",
    "        scheight += .01\n",
    "\n",
    "# define reverse_scrolling to reverse the scroll\n",
    "def reverse_scrolling():\n",
    "    body = driver.find_element(By.TAG_NAME, 'body')\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        i += 1\n",
    "        if i >= 25:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define extract_data to extract data using driver\n",
    "def extract_data(driver):\n",
    "\n",
    "    driver.implicitly_wait(20)\n",
    "    driver.refresh()\n",
    "    scrolling()\n",
    "\n",
    "    # get the data item using XPATH selector, wait up for 30 secs if it exceeds it will issue an exception\n",
    "    # data_item = wait(driver, 30).until(EC.presence_of_all_elements_located((By.XPATH, '//div[contains(@class, \"css-12sieg3\")]')))\n",
    "    data_item = wait(driver, 30).until(EC.presence_of_all_elements_located(('xpath', '//div[contains(@class, \"css-12sieg3\")]')))\n",
    "\n",
    "    # if the data items do not add up to 80 it will repeat the data retrieval process\n",
    "    if len(data_item) != 80:\n",
    "        driver.refresh()\n",
    "        driver.implicitly_wait(10)\n",
    "        scrolling()\n",
    "\n",
    "        # data_item = wait(driver, 30).until(EC.presence_of_all_elements_located((By.XPATH, '//div[contains(@class, \"css-12sieg3\")]')))\n",
    "        data_item = wait(driver, 30).until(EC.presence_of_all_elements_located(('xpath', '//div[contains(@class, \"css-12sieg3\")]')))\n",
    "\n",
    "    # loop to extract attribute data using XPATH selector\n",
    "    for item in tqdm(data_item):\n",
    "\n",
    "        # element = wait(item, 10).until(EC.presence_of_element_located((By.XPATH, './/div[@class=\"css-y5gcsw\"]')))\n",
    "        element = wait(item, 10).until(EC.presence_of_element_located(('xpath', './/div[@class=\"css-y5gcsw\"]')))\n",
    "\n",
    "        name = element.find_element(By.XPATH, './/div[@class=\"prd_link-product-name css-3um8ox\"]').text\n",
    "        price = element.find_element(By.XPATH, './/div[@class=\"prd_link-product-price css-1ksb19c\"]').text\n",
    "        location = element.find_element(By.XPATH, './/span[@class=\"prd_link-shop-loc css-1kdc32b flip\"]').text\n",
    "        try:\n",
    "            rating = element.find_element(By.XPATH, './/span[@class=\"prd_rating-average-text css-t70v7i\"]').text\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        try:\n",
    "            sold = element.find_element(By.XPATH, './/span[@class=\"prd_label-integrity css-1duhs3e\"]').text\n",
    "        except:\n",
    "            sold = None    \n",
    "\n",
    "        details_link = element.find_element(By.XPATH, './/div[@class=\"css-1f2quy8\"]/a').get_property('href')\n",
    "\n",
    "        # store data to the dictionary\n",
    "        data = {\n",
    "            'name': name,\n",
    "            'price': price,\n",
    "            'location': location,\n",
    "            'rating': rating,\n",
    "            'sold': sold,\n",
    "            'details_link': details_link\n",
    "        }\n",
    "\n",
    "        # append data to product_data\n",
    "        product_data.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# loop to scraping process \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mwhile\u001b[39;00m stop \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m pages:\n\u001b[1;32m----> 5\u001b[0m     extract_data(driver)\n\u001b[0;32m      7\u001b[0m     \u001b[39m# get the next button element using CSS selector, wait up for 60 secs if it exceeds it will issue an exception\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m, in \u001b[0;36mextract_data\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m      6\u001b[0m scrolling()\n\u001b[0;32m      8\u001b[0m \u001b[39m# get the data item using XPATH selector, wait up for 30 secs if it exceeds it will issue an exception\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# data_item = wait(driver, 30).until(EC.presence_of_all_elements_located((By.XPATH, '//div[contains(@class, \"css-12sieg3\")]')))\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m data_item \u001b[39m=\u001b[39m wait(driver, \u001b[39m30\u001b[39;49m)\u001b[39m.\u001b[39;49muntil(EC\u001b[39m.\u001b[39;49mpresence_of_all_elements_located((\u001b[39m'\u001b[39;49m\u001b[39mxpath\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m//div[contains(@class, \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcss-12sieg3\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m)]\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[0;32m     12\u001b[0m \u001b[39m# if the data items do not add up to 80 it will repeat the data retrieval process\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data_item) \u001b[39m!=\u001b[39m \u001b[39m80\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:95\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m>\u001b[39m end_time:\n\u001b[0;32m     94\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "stop = 1\n",
    "\n",
    "# loop to scraping process \n",
    "while stop <= pages:\n",
    "    extract_data(driver)\n",
    "\n",
    "    # get the next button element using CSS selector, wait up for 60 secs if it exceeds it will issue an exception\n",
    "    try:\n",
    "        next_page = wait(driver, 60).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '[aria-label=\"Laman berikutnya\"]')))\n",
    "    except:\n",
    "        driver.refresh()\n",
    "        scrolling()\n",
    "        reverse_scrolling()\n",
    "        scrolling()\n",
    "        next_page = wait(driver, 60).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '[aria-label=\"Laman berikutnya\"]')))\n",
    "    \n",
    "    # click the next_page button\n",
    "    try:\n",
    "        next_page.click()\n",
    "    except:\n",
    "        break\n",
    "\n",
    "    stop += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "df = pd.DataFrame(product_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "now = datetime.datetime.today().strftime('%d-%m-%Y')\n",
    "\n",
    "# export data to csv and json\n",
    "df.to_csv(f'sample_data_{now}.csv', index=False)\n",
    "df.to_json(f'sample_data_{now}.json', orient='records')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
